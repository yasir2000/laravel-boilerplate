# ============================================================================
# Multi-LLM Configuration for Laravel HR Boilerplate
# ============================================================================

# AI Agents System
AI_AGENTS_ENABLED=true
AI_AGENTS_BASE_URL=http://localhost:8001
AI_AGENTS_TIMEOUT=30
AI_AGENTS_API_TOKEN=your_secure_api_token_here

# Default LLM Provider
AI_DEFAULT_LLM_PROVIDER=openai

# ============================================================================
# OpenAI Configuration
# ============================================================================
OPENAI_ENABLED=true
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_API_BASE=https://api.openai.com/v1
OPENAI_DEFAULT_MODEL=gpt-4o-mini

# ============================================================================
# Anthropic (Claude) Configuration
# ============================================================================
ANTHROPIC_ENABLED=false
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_API_BASE=https://api.anthropic.com/v1
ANTHROPIC_DEFAULT_MODEL=claude-3-5-haiku-20241022

# ============================================================================
# Google AI (Gemini) Configuration
# ============================================================================
GOOGLE_AI_ENABLED=false
GOOGLE_AI_API_KEY=your_google_ai_api_key_here
GOOGLE_AI_API_BASE=https://generativelanguage.googleapis.com/v1beta
GOOGLE_AI_DEFAULT_MODEL=gemini-1.5-flash

# ============================================================================
# Mistral Configuration
# ============================================================================
MISTRAL_ENABLED=false
MISTRAL_API_KEY=your_mistral_api_key_here
MISTRAL_API_BASE=https://api.mistral.ai/v1
MISTRAL_DEFAULT_MODEL=mistral-small-latest

# ============================================================================
# Ollama (Local Models) Configuration
# ============================================================================
OLLAMA_ENABLED=false
OLLAMA_API_BASE=http://localhost:11434
OLLAMA_DEFAULT_MODEL=llama3.2:latest
OLLAMA_AUTO_PULL=true
OLLAMA_KEEP_ALIVE=5m

# ============================================================================
# Agent-Specific LLM Assignments
# ============================================================================
HR_AGENT_PRIMARY_LLM=openai:gpt-4o-mini
HR_AGENT_FALLBACK_LLM=ollama:llama3.2:latest

PROJECT_AGENT_PRIMARY_LLM=anthropic:claude-3-5-haiku-20241022
PROJECT_AGENT_FALLBACK_LLM=ollama:llama3.1:8b

ANALYTICS_AGENT_PRIMARY_LLM=google:gemini-1.5-flash
ANALYTICS_AGENT_FALLBACK_LLM=ollama:llama3.1:70b

WORKFLOW_AGENT_PRIMARY_LLM=openai:gpt-4o
WORKFLOW_AGENT_FALLBACK_LLM=ollama:mistral:latest

INTEGRATION_AGENT_PRIMARY_LLM=mistral:mistral-small-latest
INTEGRATION_AGENT_FALLBACK_LLM=ollama:codellama:latest

NOTIFICATION_AGENT_PRIMARY_LLM=openai:gpt-3.5-turbo
NOTIFICATION_AGENT_FALLBACK_LLM=ollama:neural-chat:latest

# ============================================================================
# Load Balancing & Failover
# ============================================================================
LLM_LOAD_BALANCING=true
LLM_LOAD_BALANCE_STRATEGY=round_robin
LLM_FAILOVER_ENABLED=true

# ============================================================================
# Cost Management
# ============================================================================
LLM_COST_TRACKING=true
LLM_DAILY_BUDGET=50.0
LLM_MONTHLY_BUDGET=1000.0

# ============================================================================
# Performance Optimization
# ============================================================================
LLM_CACHING=true
LLM_CACHE_TTL=3600
LLM_BATCHING=true
LLM_MAX_BATCH_SIZE=10
LLM_BATCH_TIMEOUT=5

# ============================================================================
# AI Agents Database Configuration
# ============================================================================
AI_AGENTS_DB_CONNECTION=sqlite
AI_AGENTS_DB_PATH=database/ai_agents.sqlite

# For production, consider using MySQL:
# AI_AGENTS_DB_CONNECTION=mysql
# AI_AGENTS_DB_HOST=127.0.0.1
# AI_AGENTS_DB_PORT=3306
# AI_AGENTS_DB_DATABASE=ai_agents
# AI_AGENTS_DB_USERNAME=your_username
# AI_AGENTS_DB_PASSWORD=your_password

# ============================================================================
# Dashboard Configuration
# ============================================================================
AI_DASHBOARD_REFRESH_RATE=30000
AI_DASHBOARD_EXTJS_CDN=https://cdn.sencha.com/ext/gpl/7.0.0

# ============================================================================
# Advanced Configuration
# ============================================================================
AI_AGENTS_LOG_LEVEL=info
AI_AGENTS_DEBUG=false
AI_AGENTS_TEST_MODE=false
AI_AGENTS_MOCK=false

# Maximum concurrent workflows
AI_AGENTS_MAX_CONCURRENT_WORKFLOWS=5

# Workflow timeout in seconds
AI_AGENTS_WORKFLOW_TIMEOUT=1800

# Agent timeout in seconds
AI_AGENTS_AGENT_TIMEOUT=15

# Auto retry failed operations
AI_AGENTS_AUTO_RETRY=true

# Cache TTL for agent data in seconds
AI_AGENTS_CACHE_TTL=300

# Maximum memory per agent in MB
AI_AGENTS_MAX_MEMORY=512

# ============================================================================
# Auto Workflow Triggers
# ============================================================================
AI_AUTO_EMPLOYEE_ONBOARDING=true
AI_AUTO_LEAVE_PROCESSING=true
AI_AUTO_PROJECT_OPTIMIZATION=false
AI_AUTO_ANALYTICS=true

# ============================================================================
# Integration Settings
# ============================================================================
AI_INTEGRATION_EXTERNAL_HR=false
AI_INTEGRATION_PAYROLL=false
AI_INTEGRATION_SYNC_FREQUENCY=hourly

# ============================================================================
# Security Settings
# ============================================================================
AI_RATE_LIMIT_PER_MINUTE=60
AI_BURST_LIMIT=10
AI_ENCRYPT_SENSITIVE_DATA=true
AI_ENCRYPT_COMMUNICATION=true

# Allowed IPs for AI agents (comma-separated)
AI_ALLOWED_IPS=127.0.0.1,::1

# ============================================================================
# Monitoring & Health Checks
# ============================================================================
AI_HEALTH_CHECK_INTERVAL=300
AI_PERFORMANCE_TRACKING=true
AI_ERROR_REPORTING=true
AI_METRICS_RETENTION=30

# ============================================================================
# Example Usage Instructions
# ============================================================================
# 
# 1. Choose your primary LLM provider and set AI_DEFAULT_LLM_PROVIDER
# 2. Enable at least one provider by setting its _ENABLED=true
# 3. Add your API keys for enabled providers
# 4. Configure agent-specific LLM assignments if desired
# 5. Adjust cost limits based on your budget
# 6. For local models, install and run Ollama first
# 7. Run: php artisan migrate to create LLM metrics table
# 8. Test with: curl http://localhost:8000/api/test/llm/health
#
# Example Ollama setup:
# - Install Ollama: https://ollama.ai/download
# - Pull models: ollama pull llama3.2:latest
# - Enable: OLLAMA_ENABLED=true
#
# ============================================================================